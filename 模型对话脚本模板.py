from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer
import torch
import threading
import time

class ChatAssistant:
    def __init__(self, model_path="nlp\models\Qwen2.5-0.5B-Instruct"):
        # åˆå§‹åŒ–æ¨¡å‹å’Œåˆ†è¯å™¨
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16 if self.device == "cuda" else torch.float32,
            device_map="auto",
            trust_remote_code=True
        )
        self.history = []
        print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° {self.device.upper()} è®¾å¤‡")

    def generate_stream(self, query, max_length=512, temperature=0.7, top_p=0.9):
        # æ„å»ºè¾“å…¥
        input_ids = self.tokenizer.encode(
            f"<|User|>: {query}\n<|Bot|>:",
            return_tensors="pt"
        ).to(self.device)
        
        # æµå¼è¾“å‡ºè®¾ç½®
        streamer = TextIteratorStreamer(self.tokenizer, skip_prompt=True)
        generation_kwargs = {
            "input_ids": input_ids,
            "max_new_tokens": max_length,
            "temperature": temperature,
            "top_p": top_p,
            "streamer": streamer,
            "pad_token_id": self.tokenizer.eos_token_id
        }
        
        # å¯åŠ¨ç”Ÿæˆçº¿ç¨‹
        thread = threading.Thread(target=self.model.generate, kwargs=generation_kwargs)
        thread.start()
        
        # æµå¼è¾“å‡ºç»“æœ
        generated_text = ""
        print("ğŸ¤–: ", end="", flush=True)
        for new_text in streamer:
            generated_text += new_text
            print(new_text, end="", flush=True)
            yield generated_text
        
        # ä¿å­˜å¯¹è¯å†å²
        self.history.append((query, generated_text))
        if len(self.history) > 5:  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯
            self.history.pop(0)

    def chat_loop(self):
        print("æ¬¢è¿ä½¿ç”¨DeepSeekå¯¹è¯åŠ©æ‰‹ï¼è¾“å…¥'exit'é€€å‡º")
        while True:
            try:
                user_input = input("\nğŸ‘¤: ")
                if user_input.lower() in ["exit", "quit"]:
                    break
                
                start_time = time.time()
                print("ç”Ÿæˆä¸­...", end="\r")
                
                # æµå¼ç”Ÿæˆ
                for response in self.generate_stream(user_input):
                    pass  # å®æ—¶è¾“å‡ºå·²é€šè¿‡æµå¼å¤„ç†
                
                print(f"\nâ±ï¸ å“åº”æ—¶é—´ï¼š{time.time()-start_time:.2f}s")
                
            except KeyboardInterrupt:
                print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"\nâŒ ç”Ÿæˆé”™è¯¯ï¼š{str(e)}")
                continue

if __name__ == "__main__":
    # åˆå§‹åŒ–åŠ©æ‰‹
    assistant = ChatAssistant()
    
    # å¯åŠ¨å¯¹è¯
    assistant.chat_loop() 